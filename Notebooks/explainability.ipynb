{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d80a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from background_process import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from skimage.filters import threshold_otsu as otsu\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "from scipy.ndimage import center_of_mass\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re, ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2d258-6517-470f-996e-7573c260379e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CheXpert Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84a3235-5a0b-48f3-88c9-ea80a8cf93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_file_name(img_path):\n",
    "    name = os.path.basename(img_path)\n",
    "    pre = os.path.dirname(img_path)\n",
    "\n",
    "    name = name.split('.')[0] + '.png' if not name.endswith('.png') else name\n",
    "    name = 'PROCESSED_' + name\n",
    "    return os.path.join(pre, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602955b6-060d-4ed9-a43a-da0488a39f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chex = pd.read_csv('/Data/CheX_Data/chexpertchestxrays-u20210408/train_cheXbert_w_views.csv')\n",
    "\n",
    "# only frontal images and no empty pneumonia values\n",
    "chex = chex[(chex.ViewAgreement == True) & (chex['Frontal/Lateral'] == 'Frontal') & (~chex.Pneumonia.isna())]\n",
    "\n",
    "# after processing using CXR_Processor\n",
    "chex['Processed_Path'] = chex.Path.apply(get_chex_img_path).apply(processed_file_name)\n",
    "chex['Processed_Exists'] = chex['Processed_Path'].apply(os.path.isfile)\n",
    "chex = chex[chex['Processed_Exists'] == True]     \n",
    "\n",
    "# drop uncertain diagnoses\n",
    "chex = chex[chex.Pneumonia.isin((0,1))]\n",
    "\n",
    "chex['Patient'] = chex.Path.str[20:32]\n",
    "\n",
    "chex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce980b8d-15d2-4272-abb6-7f2fff2295db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chex['Pneumonia'].value_counts(normalize=True) * 100\n",
    "chex['Pneumonia'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1134600b-2e7b-4c76-8426-7dab3433d0d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# VinDR Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a60d28b-6ecf-48e0-a3ba-aa64a25aba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before processing\n",
    "\n",
    "vindr = pd.read_csv('/Data/VinDR_Data/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_merged.csv')\n",
    "\n",
    "positive_df = vindr[vindr['Pneumonia'] == 1]\n",
    "negative_df = vindr[vindr['Pneumonia'] == 0].sample(2 * len(positive_df), random_state=0)\n",
    "\n",
    "new_df = pd.concat([positive_df, negative_df]).reset_index(drop=True)\n",
    "new_df.to_csv('/Data/VinDR_Data/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_merged_pneumonia.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd5360-f1d2-4380-9fe3-b85294ec63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after processing\n",
    "\n",
    "vindr = pd.read_csv('/Data/VinDR_Data/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_merged_pneumonia.csv')\n",
    "\n",
    "vindr['Processed_Path'] = vindr.apply(get_vindr_img_path, axis=1).apply(processed_file_name)\n",
    "vindr['Processed_Exists'] = vindr['Processed_Path'].apply(os.path.isfile)\n",
    "vindr = vindr[vindr['Processed_Exists'] == True]\n",
    "\n",
    "vindr['Patient'] = vindr.image_id\n",
    "vindr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab3b5e-ccc0-4da5-845e-3743fe20dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vindr['Pneumonia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744a8c50-d3f9-4e97-a9b3-e342b8c7e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance classes\n",
    "\n",
    "vindr_positive = vindr[vindr['Pneumonia'] == 1]\n",
    "vindr_negative = vindr[vindr['Pneumonia'] == 0].sample(len(vindr_positive), random_state=0)\n",
    "#vindr_negative = vindr[vindr['Pneumonia'] == 0].sample(len(vindr_positive)*2, random_state=0) # twice as many negative \n",
    "\n",
    "vindr = pd.concat([vindr_positive, vindr_negative])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ca8f0-e143-4f75-9fa4-f60edcc0a3a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PadChest Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af811bc-ac1f-4183-bb16-b71f1e6006bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before processing\n",
    "\n",
    "pad = pd.read_csv('/Data/BIMCV-PadChest-FULL/PADCHEST_chest_x_ray_images_labels_w_views.csv')\n",
    "pad = pad[(pad.ViewAgreement == True) & (pad['Frontal/Lateral'] == 'Frontal') & (~pad.Labels.isna())]\n",
    "\n",
    "pad['Pneumonia'] = pad.Labels.apply(lambda labels : 1 if 'pneumonia' in labels else 0)\n",
    "\n",
    "positive_df = pad[pad['Pneumonia'] == 1]\n",
    "negative_df = pad[pad['Pneumonia'] == 0].sample(2 * len(positive_df), random_state=0)\n",
    "new_df = pd.concat([positive_df, negative_df])\n",
    "\n",
    "new_df.to_csv('/Data/BIMCV-PadChest-FULL/PADCHEST_chest_x_ray_images_pneumonia.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f84172-22ed-4b92-ab8f-07e68fa075c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after processing\n",
    "\n",
    "pad = pd.read_csv('/Data/BIMCV-PadChest-FULL/PADCHEST_chest_x_ray_images_pneumonia.csv')\n",
    "\n",
    "pad['Processed_Path'] = pad.apply(get_pad_img_path, axis=1).apply(processed_file_name)\n",
    "pad['Processed_Exists'] = pad['Processed_Path'].apply(os.path.isfile)\n",
    "pad = pad[pad['Processed_Exists'] == True]\n",
    "\n",
    "pad['Patient'] = pad.PatientID\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea0f4d-8ba2-4c62-93e5-698475bb8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad['Pneumonia'].value_counts(normalize=True) * 100\n",
    "pad['Pneumonia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c99788-3cd4-425a-8aa3-88e3308d4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with MIMIC LLM + VinDr test set\n",
    "\n",
    "pad_positive = pad[pad['Pneumonia'] == 1]\n",
    "pad_negative = pad[pad['Pneumonia'] == 0].sample(len(pad_positive), random_state=0)\n",
    "pad_merge = pd.concat([pad_positive, pad_negative])\n",
    "\n",
    "pad_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89489fd1-99e7-4280-b662-129eb745c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR balance classes with CheXpert\n",
    "\n",
    "pad_positive = pad[pad['Pneumonia'] == 1]\n",
    "total_positive = len(pad_positive) + len(chex[chex['Pneumonia'] == 1])\n",
    "\n",
    "diff = total_positive - len(chex[chex['Pneumonia'] == 0])\n",
    "#diff = (2 * total_positive) - len(chex[chex['Pneumonia'] == 0]) # twice as many negative\n",
    "\n",
    "pad_negative = pad[pad['Pneumonia'] == 0].sample(diff, random_state=0)\n",
    "\n",
    "pad = pd.concat([pad_positive, pad_negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df52cc1-13c0-44a4-acd3-e052423c8bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad['Pneumonia'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f92e4-f504-44e3-8932-1079907ce374",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Pneumonia positive: {len(pad[pad[\"Pneumonia\"] == 1]) + len(chex[chex[\"Pneumonia\"] == 1])}')\n",
    "print(f'Pneumonia negative: {len(pad[pad[\"Pneumonia\"] == 0]) + len(chex[chex[\"Pneumonia\"] == 0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448544f-13f4-4c47-8d39-57dc0693a175",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# NIH Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aec2de76-6229-4480-9fe5-f9826c6ffed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before processing\n",
    "\n",
    "nih = pd.read_csv('/Data/NIH_Data/Data_Entry_2017.csv')\n",
    "nih['Pneumonia'] = nih['Finding Labels'].apply(lambda labels : 1 if 'Pneumonia' in labels else 0)\n",
    "\n",
    "positive_df = nih[nih['Pneumonia'] == 1]\n",
    "negative_df = nih[nih['Pneumonia'] == 0].sample(2 * len(positive_df), random_state=0)\n",
    "new_df = pd.concat([positive_df, negative_df])\n",
    "\n",
    "new_df.to_csv('/Data/NIH_Data/Data_Entry_2017_pneumonia.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa89bc81-334e-467d-b02f-eff199ebc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after processing\n",
    "\n",
    "nih = pd.read_csv('/Data/NIH_Data/Data_Entry_2017_pneumonia.csv')\n",
    "\n",
    "nih['Processed_Path'] = nih['Image Index'].apply(get_nih_img_path).apply(processed_file_name)\n",
    "nih['Processed_Exists'] = nih['Processed_Path'].apply(os.path.isfile)\n",
    "nih = nih[nih['Processed_Exists'] == True]\n",
    "\n",
    "nih['Patient'] = nih['Patient ID']\n",
    "nih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d126f91-2373-4f79-b241-83258634f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "nih.Pneumonia.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2940a71-a7e3-4ebb-9f71-7465375c2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with MIMIC LLM + VinDr test set\n",
    "\n",
    "nih_positive = nih[nih['Pneumonia'] == 1]\n",
    "nih_negative = nih[nih['Pneumonia'] == 0].sample(len(nih_positive), random_state=0)\n",
    "nih_merge = pd.concat([nih_positive, nih_negative])\n",
    "\n",
    "nih_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e920e-ed01-430a-9610-d54cb8fb782c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MIMIC Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73087e9-a801-4964-bb34-0c960c9ca3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia.csv')\n",
    "mimic['dicom_id'] = mimic.Path.apply(lambda path: os.path.basename(path)[:-4])\n",
    "\n",
    "mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3d805-22ad-45fd-b266-f31975f1c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each image tagged with quality issues (bool), corrected views (FRONT/LAT), and gender mismatch in metadata (bool)\n",
    "# performed in previous study of ours. doi: 10.1371/journal.pdig.0000835\n",
    "\n",
    "mimic_meta = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-2.0.0-metadata-augmented-trimmed.csv')\n",
    "mimic_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb356083-7c86-48f1-8e4f-4ae94f369f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only retain high-quality, frontal images\n",
    "def mimic_include(dicom_id):\n",
    "    row = mimic_meta[mimic_meta['dicom_id'] == dicom_id].iloc[0]\n",
    "    if row['CorrectedView'] == 'FRONTAL' and not row['QualityIssue'] and not row['GenderMismatch']:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4f61a-e422-4a83-85fa-c31dd71c84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic['Keep'] = mimic['dicom_id'].apply(mimic_include)\n",
    "mimic = mimic[mimic['Keep'] == True]\n",
    "mimic\n",
    "\n",
    "#mimic.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia-frontal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b58ca-7aff-442e-b948-a5499ee6144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after processing\n",
    "\n",
    "mimic = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia-frontal.csv')\n",
    "\n",
    "mimic['Processed_Path'] = mimic.Path.apply(processed_file_name)\n",
    "mimic['Processed_Exists'] = mimic['Processed_Path'].apply(os.path.isfile)\n",
    "mimic = mimic[mimic['Processed_Exists'] == True]   \n",
    "\n",
    "mimic\n",
    "\n",
    "#mimic.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia-frontal-processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42de89a-cf97-461d-8b26-e7ae08f17811",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic['Pneumonia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2a0c67-2f20-413c-af2c-228becdbf884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes\n",
    "\n",
    "mimic_positive = mimic[mimic['Pneumonia'] == 1]\n",
    "mimic_negative = mimic[mimic['Pneumonia'] == 0].sample(len(mimic_positive), random_state=0)\n",
    "\n",
    "mimic = pd.concat([mimic_positive, mimic_negative])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9eeef8-afc6-42fa-b468-106cea235087",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MIMIC LLM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa650b88-eea5-4a76-b4d4-5a8e5781505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_llm = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia-full-wreports_llm_complete.csv')\n",
    "mimic_llm = mimic_llm[mimic_llm.LLM_class.isin((0,1))]\n",
    "\n",
    "mimic_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1dade4-f234-4071-b295-9fbc3f0b5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_llm['Keep'] = mimic_llm['dicom_id'].apply(mimic_include)\n",
    "mimic_llm = mimic_llm[mimic_llm['Keep'] == True]\n",
    "mimic_llm\n",
    "\n",
    "#mimic_llm.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia-full-wreports_llm_complete_frontal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba2429-f579-43b6-b16d-51d9287f817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_llm = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia-full-wreports_llm_complete_frontal.csv')\n",
    "\n",
    "mimic_llm['Processed_Path'] = mimic_llm.Path.apply(processed_file_name)\n",
    "mimic_llm['Processed_Exists'] = mimic_llm['Processed_Path'].apply(os.path.isfile)\n",
    "mimic_llm = mimic_llm[mimic_llm['Processed_Exists'] == True]\n",
    "\n",
    "mimic_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c400da9-aa76-4be6-839a-18c0b8aacf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_llm.LLM_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f0feb-9f85-4ffd-a689-2d3b21e9ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes\n",
    "\n",
    "mimic_positive = mimic_llm[mimic_llm.LLM_class == 1]\n",
    "mimic_negative = mimic_llm[mimic_llm.LLM_class == 0].sample(len(mimic_positive), random_state=0)\n",
    "\n",
    "mimic = pd.concat([mimic_positive, mimic_negative])\n",
    "mimic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49226c70-f5cf-45e6-b2f3-55dd368211c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RSNA Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8594b9-9ebc-4293-a300-a2afd6589378",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsna = pd.read_csv('/Data/RSNA_Data/stage_2_train_labels.csv')\n",
    "\n",
    "rsna['Processed_Path'] = rsna.patientId.apply(get_rsna_img_path).apply(processed_file_name)\n",
    "rsna['Processed_Exists'] = rsna['Processed_Path'].apply(os.path.isfile)\n",
    "rsna = rsna[rsna['Processed_Exists'] == True]\n",
    "\n",
    "rsna['Patient'] = rsna.patientId\n",
    "rsna['Pneumonia'] = rsna.Target\n",
    "\n",
    "rsna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e632c6-0664-47f9-8723-34696d7ebd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsna.Pneumonia.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b32bc-2c18-4b03-894f-080650bb1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsna_positive = rsna[rsna['Pneumonia'] == 1]\n",
    "rsna_negative = rsna[rsna['Pneumonia'] == 0].sample(len(rsna_positive), random_state=0)\n",
    "rsna_merge = pd.concat([rsna_positive, rsna_negative])\n",
    "\n",
    "rsna_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c5091-009e-420a-8218-914d54428ed8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train-test-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75bba8a7-7266-4d89-9be0-1ef191764c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic['Pneumonia'] = mimic.LLM_class # for LLM labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "786c1021-38b3-492e-9893-c3eecff20399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_filtered = chex[['Processed_Path', 'Pneumonia', 'Patient']]\n",
    "#data_filtered = pad[['Processed_Path', 'Pneumonia', 'Patient']]\n",
    "#data_filtered = pad_merge[['Processed_Path', 'Pneumonia', 'Patient']]\n",
    "#data_filtered = nih_merge[['Processed_Path', 'Pneumonia', 'Patient']]\n",
    "#data_filtered = rsna_merge[['Processed_Path', 'Pneumonia', 'Patient']]\n",
    "#data_filtered = mimic[['Processed_Path', 'Pneumonia', 'Patient']]\n",
    "data_filtered = vindr[['Processed_Path', 'Pneumonia', 'Patient']]\n",
    "\n",
    "data_filtered['Pneumonia'] = data_filtered['Pneumonia'].astype(int)\n",
    "\n",
    "# assign label as the mode for each patient for stratification\n",
    "patient_labels = data_filtered.groupby('Patient')['Pneumonia'].agg(lambda x: x.mode().iloc[0])\n",
    "data_filtered = data_filtered.merge(patient_labels.rename('Patient_Label'), on='Patient')\n",
    "\n",
    "unique_patients = data_filtered[['Patient', 'Patient_Label']].drop_duplicates()\n",
    "\n",
    "# split patients (80-20) and balance labels\n",
    "train_patients, val_test_patients = train_test_split(\n",
    "    unique_patients,\n",
    "    test_size=.2,\n",
    "    stratify=unique_patients['Patient_Label'],\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# validation and test sets (50-50 split of 20%)\n",
    "val_patients, test_patients = train_test_split(\n",
    "    val_test_patients,\n",
    "    test_size=.5,\n",
    "    stratify=val_test_patients['Patient_Label'],\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "train_data = data_filtered[data_filtered['Patient'].isin(train_patients['Patient'])]\n",
    "val_data = data_filtered[data_filtered['Patient'].isin(val_patients['Patient'])]\n",
    "test_data = data_filtered[data_filtered['Patient'].isin(test_patients['Patient'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc384062-38ac-458c-8f4b-209b8275f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distribution = train_data['Pneumonia'].value_counts(normalize=True) * 100\n",
    "val_distribution = val_data['Pneumonia'].value_counts(normalize=True) * 100\n",
    "test_distribution = test_data['Pneumonia'].value_counts(normalize=True) * 100\n",
    "\n",
    "train_distribution, val_distribution, test_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59a70448-2330-43e4-9bd5-73377acd5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no patient data leakage\n",
    "train_patients_set = set(train_data['Patient'])\n",
    "val_patients_set = set(val_data['Patient'])\n",
    "test_patients_set = set(test_data['Patient'])\n",
    "\n",
    "overlap_train_val = train_patients_set.intersection(val_patients_set)\n",
    "overlap_train_test = train_patients_set.intersection(test_patients_set)\n",
    "overlap_val_test = val_patients_set.intersection(test_patients_set)\n",
    "\n",
    "assert len(overlap_train_val) == 0, 'leakage between train and val'\n",
    "assert len(overlap_train_test) == 0, 'leakage between train and test'\n",
    "assert len(overlap_val_test) == 0, 'leakage between val and test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab1f0bb-d242-4f2a-befa-f327b23dc0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.rename(columns={'Processed_Path': 'Path',\n",
    "                           'Pneumonia': 'Label'}, inplace=True)\n",
    "val_data.rename(columns={'Processed_Path': 'Path',\n",
    "                           'Pneumonia': 'Label'}, inplace=True)\n",
    "test_data.rename(columns={'Processed_Path': 'Path',\n",
    "                           'Pneumonia': 'Label'}, inplace=True)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e479bba3-02af-4621-beca-6e88e2928a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.to_csv('/Data/CheX_Data/train.csv', index=False)\n",
    "#val_data.to_csv('/Data/CheX_Data/validation.csv', index=False)\n",
    "#test_data.to_csv('/Data/CheX_Data/test.csv', index=False)\n",
    "\n",
    "#train_data.to_csv('/Data/BIMCV-PadChest-FULL/train.csv', index=False)\n",
    "#val_data.to_csv('/Data/BIMCV-PadChest-FULL/validation.csv', index=False)\n",
    "#test_data.to_csv('/Data/BIMCV-PadChest-FULL/test.csv', index=False)\n",
    "\n",
    "#train_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/train.csv', index=False)\n",
    "#val_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/validation.csv', index=False)\n",
    "#test_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/test.csv', index=False)\n",
    "\n",
    "#train_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/train_nlp.csv', index=False)\n",
    "#val_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/validation_nlp.csv', index=False)\n",
    "#test_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/test_nlp.csv', index=False)\n",
    "#train_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/train_llm.csv', index=False)\n",
    "#val_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/validation_llm.csv', index=False)\n",
    "#test_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/test_llm.csv', index=False)\n",
    "\n",
    "#train_data.to_csv('/Data/VinDR_Data/train.csv', index=False)\n",
    "#val_data.to_csv('/Data/VinDR_Data/validation.csv', index=False)\n",
    "#test_data.to_csv('/Data/VinDR_Data/test.csv', index=False)\n",
    "\n",
    "#train_data.to_csv('/Data/NIH_Data/train.csv', index=False)\n",
    "#val_data.to_csv('/Data/NIH_Data/validation.csv', index=False)\n",
    "#test_data.to_csv('/Data/NIH_Data/test.csv', index=False)\n",
    "\n",
    "train_data.to_csv('/Data/RSNA_Data/train.csv', index=False)\n",
    "val_data.to_csv('/Data/RSNA_Data/validation.csv', index=False)\n",
    "test_data.to_csv('/Data/RSNA_Data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2778807f-6e35-47fa-8cd7-c36e59735ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced sets\n",
    "\n",
    "#train_data.to_csv('/Data/VinDR_Data/train_imbalanced.csv', index=False)\n",
    "#val_data.to_csv('/Data/VinDR_Data/validation_imbalanced.csv', index=False)\n",
    "#test_data.to_csv('/Data/VinDR_Data/test_imbalanced.csv', index=False)\n",
    "\n",
    "#train_data.to_csv('/Data/BIMCV-PadChest-FULL/train_imbalanced.csv', index=False)\n",
    "#val_data.to_csv('/Data/BIMCV-PadChest-FULL/validation_imbalanced.csv', index=False)\n",
    "#test_data.to_csv('/Data/BIMCV-PadChest-FULL/test_imbalanced.csv', index=False)\n",
    "\n",
    "train_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/train_imbalanced.csv', index=False)\n",
    "val_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/validation_imbalanced.csv', index=False)\n",
    "test_data.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/test_imbalanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a41efd-9cc0-4007-94bd-25c2185df4a5",
   "metadata": {},
   "source": [
    "# Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291c9ff-5482-46ba-90de-51d577b91a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "chex_train = pd.read_csv('/Data/CheX_Data/train.csv')\n",
    "pad_train = pd.read_csv('/Data/BIMCV-PadChest-FULL/train.csv')\n",
    "mimic_train = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/train.csv')\n",
    "vindr_train = pd.read_csv('/Data/VinDR_Data/train.csv')\n",
    "\n",
    "chex_val = pd.read_csv('/Data/CheX_Data/validation.csv')\n",
    "pad_val = pd.read_csv('/Data/BIMCV-PadChest-FULL/validation.csv')\n",
    "mimic_val = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/validation.csv')\n",
    "vindr_val = pd.read_csv('/Data/VinDR_Data/validation.csv')\n",
    "\n",
    "chex_test = pd.read_csv('/Data/CheX_Data/test.csv')\n",
    "pad_test = pd.read_csv('/Data/BIMCV-PadChest-FULL/test.csv')\n",
    "mimic_test = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/test.csv')\n",
    "vindr_test = pd.read_csv('/Data/VinDR_Data/test.csv')\n",
    "\n",
    "train_data = pd.concat([chex_train, pad_train, mimic_train, vindr_train])\n",
    "val_data = pd.concat([chex_val, pad_val, mimic_val, vindr_val])\n",
    "test_data = pd.concat([chex_test, pad_test, mimic_test, vindr_test])\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89578004-c5d4-4031-ac02-b09fc3e22dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Data/RSNA_Data/test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e16fe3-5def-41ab-a935-0844fb1a7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced datasets\n",
    "\n",
    "chex_train = pd.read_csv('/Data/CheX_Data/train.csv')\n",
    "pad_train = pd.read_csv('/Data/BIMCV-PadChest-FULL/train_imbalanced.csv')\n",
    "mimic_train = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/train_imbalanced.csv')\n",
    "vindr_train = pd.read_csv('/Data/VinDR_Data/train_imbalanced.csv')\n",
    "\n",
    "chex_val = pd.read_csv('/Data/CheX_Data/validation.csv')\n",
    "pad_val = pd.read_csv('/Data/BIMCV-PadChest-FULL/validation_imbalanced.csv')\n",
    "mimic_val = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/validation_imbalanced.csv')\n",
    "vindr_val = pd.read_csv('/Data/VinDR_Data/validation_imbalanced.csv')\n",
    "\n",
    "chex_test = pd.read_csv('/Data/CheX_Data/test.csv')\n",
    "pad_test = pd.read_csv('/Data/BIMCV-PadChest-FULL/test_imbalanced.csv')\n",
    "mimic_test = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/test_imbalanced.csv')\n",
    "vindr_test = pd.read_csv('/Data/VinDR_Data/test_imbalanced.csv')\n",
    "\n",
    "train_data = pd.concat([chex_train, pad_train, mimic_train, vindr_train])\n",
    "val_data = pd.concat([chex_val, pad_val, mimic_val, vindr_val])\n",
    "test_data = pd.concat([chex_test, pad_test, mimic_test, vindr_test])\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091e57a5-d961-47ce-8d1f-c6feef7049cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_test = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/test_llm.csv')\n",
    "vindr_test = pd.read_csv('/Data/VinDR_Data/test.csv')\n",
    "\n",
    "test_data = pd.concat([mimic_test, vindr_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2802cf5-0c02-411b-9d42-561cfeb3942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with MIMIC LLM + VinDr test set\n",
    "\n",
    "#vindr_test[:-1].to_csv('/Data/VinDR_Data/final_test.csv', index=False)\n",
    "\n",
    "mimic_positive = mimic_test[mimic_test['Label'] == 1].sample(70, random_state=0)\n",
    "mimic_negative = mimic_test[mimic_test['Label'] == 0].sample(70, random_state=0)\n",
    "\n",
    "mimic_test = pd.concat([mimic_positive, mimic_negative])\n",
    "\n",
    "mimic_test.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/final_test_llm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb404ede-86b7-4e52-be2e-290a066aa6aa",
   "metadata": {},
   "source": [
    "# Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a37fc175-e0c4-4b1f-af9d-6ea2e4d64d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        # patch forward method if needed\n",
    "        self.patch_forward()\n",
    "\n",
    "        # save activations and gradients\n",
    "        self.target_layer.register_forward_hook(self.save_activation)\n",
    "        self.target_layer.register_full_backward_hook(self.save_gradient)\n",
    "\n",
    "    def patch_forward(self):\n",
    "        \"\"\"\n",
    "        For models like DenseNet that use in-place ReLU operations, override the forward function to use a non in-place ReLU\n",
    "        \"\"\"\n",
    "        if hasattr(self.model, 'features') and hasattr(self.model, 'classifier'):\n",
    "            def modified_forward(model_self, x):\n",
    "                features = model_self.features(x)\n",
    "                out = F.relu(features, inplace=False)\n",
    "                out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "                out = torch.flatten(out, 1)\n",
    "                out = model_self.classifier(out)\n",
    "                return out\n",
    "\n",
    "            self.model.forward = modified_forward.__get__(self.model, type(self.model))\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach().clone()\n",
    "\n",
    "    def __call__(self, x, class_idx=None):\n",
    "        \"\"\"\n",
    "        Compute Grad-CAM for input image tensor 'x'\n",
    "        If class_idx is provided, compute for that class; otherwise, use the predicted class\n",
    "        \"\"\"\n",
    "        output = self.model(x) # forward pass\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "\n",
    "        # class to visualise\n",
    "        if class_idx is None:\n",
    "            predicted_conf, predicted_class = torch.max(probabilities, dim=1)\n",
    "            class_idx = predicted_class.item()\n",
    "            confidence = predicted_conf.item()\n",
    "        else:\n",
    "            confidence = probabilities[0, class_idx].item()\n",
    "\n",
    "        # backward pass with one-hot encoding for the target class\n",
    "        self.model.zero_grad()\n",
    "        one_hot = torch.zeros_like(output).to(output.device)\n",
    "        one_hot[0, class_idx] = 1.0\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "\n",
    "        # global average pool the gradients, combine with activations\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        grad_cam = torch.sum(weights * self.activations, dim=1).squeeze(0)\n",
    "        grad_cam = F.relu(grad_cam)  # keep only positive influence\n",
    "\n",
    "        # normalise to [0, 1]\n",
    "        grad_cam -= grad_cam.min()\n",
    "        if grad_cam.max() > 0:\n",
    "            grad_cam /= grad_cam.max()\n",
    "        grad_cam = grad_cam.cpu().numpy()\n",
    "\n",
    "        return grad_cam, class_idx, confidence\n",
    "\n",
    "def overlay_heatmap(heatmap, img, threshold=0, cmap=cv2.COLORMAP_JET):\n",
    "    heatmap[heatmap < threshold] = 0  # zero out activations below threshold\n",
    "    \n",
    "    # resize heatmap to image size\n",
    "    heatmap = cv2.resize(heatmap, (img.size[0], img.size[1]))\n",
    "\n",
    "    # heatmap to colour map\n",
    "    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cmap)\n",
    "\n",
    "    # BGR for opencv\n",
    "    img_np = np.array(img)\n",
    "    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # overlay heatmap\n",
    "    overlay = cv2.addWeighted(img_bgr, .5, heatmap_color, .5, 0)\n",
    "\n",
    "    # back to RGB for matplotlib\n",
    "    overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return heatmap, overlay_rgb\n",
    "\n",
    "def original_file_name(img_path):\n",
    "    if 'PadChest' in img_path:\n",
    "        return img_path.replace('PROCESSED_','')\n",
    "    return img_path.replace('PROCESSED_','').replace('.png', '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68e3282-1ebc-467b-b32a-93fd5f02dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {0: 'No pneumonia', 1: 'Pneumonia'}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#model = models.efficientnet_b5(pretrained=True)\n",
    "#model = models.efficientnet_b6(pretrained=True)\n",
    "#model = models.efficientnet_v2_m(pretrained=True)\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# efficientnet\n",
    "#model.classifier = nn.Sequential(\n",
    "#    nn.Linear(model.classifier[1].in_features, 512), \n",
    "#    nn.ReLU(), \n",
    "#    nn.BatchNorm1d(512), \n",
    "#    nn.Dropout(p=.3),\n",
    "#    nn.Linear(512, 2)\n",
    "#)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.classifier.in_features, 512), \n",
    "    nn.ReLU(), \n",
    "    nn.BatchNorm1d(512), \n",
    "    nn.Dropout(p=.3),\n",
    "    nn.Linear(512, 2)\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('/Data/mimic_llm_model.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "process = transforms.Compose([\n",
    "    transforms.Resize((480, 480)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.485, .456, .406], std=[.229, .224, .225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948db13f-44de-4045-8a92-49bba044a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/test_llm.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bc08d-dd50-42cf-b2b4-ac861d731f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_data.reset_index(drop=True).loc[185]\n",
    "img_path, truth = data.Path, data.Label\n",
    "\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img_tensor = process(img).unsqueeze(0).to(device)\n",
    "\n",
    "# last convolutional layer\n",
    "target_layer = model.features[-1] # efficientnet, densenet\n",
    "\n",
    "grad_cam = GradCAM(model, target_layer)\n",
    "\n",
    "heatmap, pred_class_idx, confidence = grad_cam(img_tensor)\n",
    "heatmap, overlay_rgb = overlay_heatmap(heatmap, img, threshold=0)\n",
    "\n",
    "true_class = class_labels[truth]\n",
    "pred_class = class_labels[pred_class_idx]\n",
    "\n",
    "_,ax = plt.subplots(ncols=2, figsize=(10,5), tight_layout=True)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(f'Ground truth: {true_class}')\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(overlay_rgb)\n",
    "ax[1].set_title(f'Prediction: {pred_class} ({confidence:.2%})'.title())\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "#plt.savefig('/Data/Figures/mimic_gradcam_2.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3687475d-b5a3-48de-84a4-ec2436d237b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_lung(lung_mask):\n",
    "    \"\"\"Divides lung mask into three equal portions based on height\"\"\"\n",
    "    \n",
    "    # indices of lung pixels\n",
    "    row_indices = torch.nonzero(lung_mask.sum(dim=1), as_tuple=True)[0]\n",
    "    min_idx = row_indices.min().item()\n",
    "    max_idx = row_indices.max().item()\n",
    "    lung_height = max_idx - min_idx + 1\n",
    "\n",
    "    # split boundaries\n",
    "    split1 = min_idx + lung_height // 3\n",
    "    split2 = min_idx + 2 * (lung_height // 3)\n",
    "\n",
    "    # masks for each portion\n",
    "    upper_mask = torch.zeros_like(lung_mask, dtype=torch.bool)\n",
    "    middle_mask = torch.zeros_like(lung_mask, dtype=torch.bool)\n",
    "    lower_mask = torch.zeros_like(lung_mask, dtype=torch.bool)\n",
    "\n",
    "    upper_mask[min_idx:split1, :] = lung_mask[min_idx:split1, :]\n",
    "    middle_mask[split1:split2, :] = lung_mask[split1:split2, :]\n",
    "    lower_mask[split2:max_idx + 1, :] = lung_mask[split2:max_idx + 1, :]\n",
    "\n",
    "    return upper_mask, middle_mask, lower_mask\n",
    "\n",
    "def add_fraction_text(ax, mask, fraction, color='white'):\n",
    "    \"\"\"Adds text annotation to the centre of a lung mask to show the fraction of activation\"\"\"\n",
    "\n",
    "    mask_np = mask.cpu().numpy()\n",
    "    if mask_np.sum() == 0:\n",
    "        return\n",
    "\n",
    "    # centre of mass (y, x)\n",
    "    cy, cx = center_of_mass(mask_np)\n",
    "\n",
    "    text_str = f\"{fraction:.2f}\"\n",
    "    ax.text(cx, cy, text_str,\n",
    "            color=color, ha='center', va='center',\n",
    "            fontweight='bold', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07dc33b-c903-4624-ae72-2ae19a708f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_data.reset_index(drop=True).loc[185]\n",
    "path, truth = original_file_name(data.Path), data.Label\n",
    "\n",
    "processor = CXR_Processor()\n",
    "\n",
    "original, processed = processor.load_and_process(path)\n",
    "cropped_img, cropped_mask, left_lung, right_lung = processor.crop_trunk(original, processed, .025, return_lungs=True)\n",
    "outlier_mask = processor.find_outliers(cropped_img, cropped_mask, lower_percentile=.1, outlier_thresh=.05)\n",
    "clahe_img = cv2.createCLAHE(clipLimit=2).apply(cropped_img)\n",
    "if outlier_mask is not None:\n",
    "    clahe_img[outlier_mask] = 0\n",
    "\n",
    "img = Image.fromarray(clahe_img).convert('RGB')\n",
    "img_tensor = process(img).unsqueeze(0).to(device)\n",
    "\n",
    "heatmap, pred_class_idx, confidence = grad_cam(img_tensor)\n",
    "heatmap, overlay_rgb = overlay_heatmap(heatmap, img, threshold=otsu(heatmap))\n",
    "\n",
    "true_class = class_labels[truth]\n",
    "pred_class = class_labels[pred_class_idx]\n",
    "\n",
    "_,ax = plt.subplots(ncols=3, figsize=(15,10), constrained_layout=True)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(f'Input CXR\\nGround truth: {true_class}')\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(overlay_rgb)\n",
    "ax[1].set_title(f'Grad-CAM Overlay\\nPrediction: {pred_class} ({confidence:.2%})')\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "combined_lungs = left_lung | right_lung\n",
    "heatmap[~combined_lungs.cpu()] = 0 # zero out activations outside lungs\n",
    "\n",
    "# renormalise\n",
    "heatmap -= heatmap.min()\n",
    "if heatmap.max() > 0:\n",
    "    heatmap /= heatmap.max()\n",
    "\n",
    "upper_left, middle_left, lower_left = divide_lung(left_lung)\n",
    "upper_right, middle_right, lower_right = divide_lung(right_lung)\n",
    "\n",
    "# max activations per lung zone\n",
    "frac_upper_left = heatmap[upper_left.cpu()].max().item()\n",
    "frac_middle_left = heatmap[middle_left.cpu()].max().item()\n",
    "frac_lower_left = heatmap[lower_left.cpu()].max().item()\n",
    "\n",
    "frac_upper_right = heatmap[upper_right.cpu()].max().item()\n",
    "frac_middle_right = heatmap[middle_right.cpu()].max().item()\n",
    "frac_lower_right = heatmap[lower_right.cpu()].max().item()\n",
    "\n",
    "ax[2].imshow(img)\n",
    "ax[2].imshow(heatmap, cmap='jet', alpha=.5)\n",
    "\n",
    "ax[2].contour(upper_left.cpu(), levels=[.5], colors='red', linewidths=2)\n",
    "ax[2].contour(middle_left.cpu(), levels=[.5], colors='red', linewidths=2)\n",
    "ax[2].contour(lower_left.cpu(), levels=[.5], colors='red', linewidths=2)\n",
    "\n",
    "add_fraction_text(ax[2], upper_left,  frac_upper_left)\n",
    "add_fraction_text(ax[2], middle_left,  frac_middle_left)\n",
    "add_fraction_text(ax[2], lower_left,  frac_lower_left)\n",
    "\n",
    "ax[2].contour(upper_right.cpu(), levels=[.5], colors='red', linewidths=2)\n",
    "ax[2].contour(middle_right.cpu(), levels=[.5], colors='red', linewidths=2)\n",
    "ax[2].contour(lower_right.cpu(), levels=[.5], colors='red', linewidths=2)\n",
    "\n",
    "add_fraction_text(ax[2], upper_right,  frac_upper_right)\n",
    "add_fraction_text(ax[2], middle_right,  frac_middle_right)\n",
    "add_fraction_text(ax[2], lower_right,  frac_lower_right)\n",
    "\n",
    "ax[2].axis(\"off\")\n",
    "\n",
    "#plt.savefig('/Data/Figures/mimic_pos_gradcam_loc.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365066b4-193b-491c-9689-b34c2c3cfc93",
   "metadata": {},
   "source": [
    "# MIMIC Localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb973fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gradcam(mapped_col, pred_col):\n",
    "    \"\"\"\n",
    "    Evaluate Grad-CAM heatmaps against ground truth lung zones using various metrics\n",
    "    \n",
    "    Args:\n",
    "        mapped_col : Column of dictionaries for ground truth\n",
    "        pred_col : Column of dictionaries for Grad-CAM activations\n",
    "    \"\"\"\n",
    "\n",
    "    all_mapped, all_pred = [], []\n",
    "    \n",
    "    # zone-level metrics\n",
    "    total_precision_numerator = 0\n",
    "    total_precision_denominator = 0\n",
    "    total_recall_numerator = 0\n",
    "    total_recall_denominator = 0\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "    \n",
    "    for mapped_zones, pred_zones in zip(mapped_col, pred_col):\n",
    "        mapped_array = np.array(list(mapped_zones.values()))\n",
    "        pred_array = np.array(list(pred_zones.values()))\n",
    "        \n",
    "        # global lists for aggregate metrics\n",
    "        all_mapped.extend(mapped_array)\n",
    "        all_pred.extend(pred_array)\n",
    "        \n",
    "        # intersection and union for IoU\n",
    "        intersection = np.minimum(mapped_array, pred_array).sum()\n",
    "        union = np.maximum(mapped_array, pred_array).sum()\n",
    "        total_intersection += intersection\n",
    "        total_union += union\n",
    "        \n",
    "        # precision\n",
    "        precision_numerator = (mapped_array * pred_array).sum()\n",
    "        precision_denominator = pred_array.sum()\n",
    "        total_precision_numerator += precision_numerator\n",
    "        total_precision_denominator += precision_denominator\n",
    "        \n",
    "        # recall\n",
    "        recall_numerator = (mapped_array * pred_array).sum()\n",
    "        recall_denominator = mapped_array.sum()\n",
    "        total_recall_numerator += recall_numerator\n",
    "        total_recall_denominator += recall_denominator\n",
    "    \n",
    "    # aggregate computation\n",
    "    all_mapped = np.array(all_mapped)\n",
    "    all_pred = np.array(all_pred)\n",
    "    \n",
    "    # weighted match (sum of activations in ground truth zones)\n",
    "    mapped_indices = all_mapped == 1\n",
    "    weighted_match = all_pred[mapped_indices].sum() / mapped_indices.sum() if mapped_indices.sum() > 0 else 0\n",
    "    \n",
    "    # MSE\n",
    "    mse = np.mean((all_mapped - all_pred) ** 2)\n",
    "    \n",
    "    # MAE\n",
    "    mae = np.mean(np.abs(all_mapped - all_pred))\n",
    "    \n",
    "    # cosine similarity\n",
    "    numerator = np.dot(all_mapped, all_pred)\n",
    "    denominator = np.sqrt(np.sum(all_mapped ** 2)) * np.sqrt(np.sum(all_pred ** 2))\n",
    "    cosine_similarity = numerator / denominator if denominator != 0 else 0\n",
    "    \n",
    "    # IoU\n",
    "    iou = total_intersection / total_union if total_union > 0 else 0\n",
    "    \n",
    "    # precision\n",
    "    localisation_precision = total_precision_numerator / total_precision_denominator if total_precision_denominator > 0 else 0\n",
    "    \n",
    "    # recall\n",
    "    localisation_recall = total_recall_numerator / total_recall_denominator if total_recall_denominator > 0 else 0\n",
    "    \n",
    "    # F1 score\n",
    "    if localisation_precision + localisation_recall > 0:\n",
    "        localisation_f1 = 2 * (localisation_precision * localisation_recall) / (localisation_precision + localisation_recall)\n",
    "    else:\n",
    "        localisation_f1 = 0\n",
    "    \n",
    "    return {\n",
    "        \"Weighted Match\": weighted_match,\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"Cosine Similarity\": cosine_similarity,\n",
    "        \"IoU\": iou,\n",
    "        \"Localisation Precision\": localisation_precision,\n",
    "        \"Localisation Recall\": localisation_recall,\n",
    "        \"Localisation F1 Score\": localisation_f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fb9ac4d-ad9f-4b2f-8f71-b00f0a4efabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map localisation strings to lung zones\n",
    "\n",
    "def assign_zones(zones, zone_type, left, right, bilateral):\n",
    "    if bilateral or not (left or right):  # no direction, map to both sides\n",
    "        zones[f\"{zone_type}_left\"] = 1\n",
    "        zones[f\"{zone_type}_right\"] = 1\n",
    "    if left:\n",
    "        zones[f\"{zone_type}_left\"] = 1\n",
    "    if right:\n",
    "        zones[f\"{zone_type}_right\"] = 1\n",
    "\n",
    "def map_pneumonia_locs(location_text):\n",
    "    # lung zones\n",
    "    zones = {\n",
    "        'upper_left': 0, 'middle_left': 0, 'lower_left': 0,\n",
    "        'upper_right': 0, 'middle_right': 0, 'lower_right': 0\n",
    "    }\n",
    "    \n",
    "    # split location into components\n",
    "    components = [comp.strip().lower() for comp in location_text.split(',')]\n",
    "    \n",
    "    # map each component\n",
    "    for comp in components:\n",
    "        # directional flags\n",
    "        left = 'left' in comp\n",
    "        right = 'right' in comp\n",
    "        bilateral = 'bilateral' in comp or 'both' in comp\n",
    "    \n",
    "        # lower zones\n",
    "        if 'bas' in comp or 'lower' in comp or 'costophrenic' in comp or 'cardiac' in comp:\n",
    "            assign_zones(zones, 'lower', left, right, bilateral)\n",
    "\n",
    "        # upper zones\n",
    "        if 'apical' in comp or 'upper' in comp:\n",
    "            assign_zones(zones, 'upper', left, right, bilateral)\n",
    "\n",
    "        # middle zones\n",
    "        if 'mid' in comp:\n",
    "            if 'middle lobe' in comp:\n",
    "                zones['middle_right'] = 1  # specific to right lung\n",
    "            else:\n",
    "                assign_zones(zones, 'middle', left, right, bilateral)\n",
    "        if 'hilar' in comp or 'bronchi' in comp:\n",
    "            assign_zones(zones, 'middle', left, right, bilateral)\n",
    "        if 'lingula' in comp:\n",
    "            zones['middle_left'] = 1  # specific to left lung\n",
    "\n",
    "        if set(zones.values()) == {0}: # no specific zones assigned\n",
    "            if bilateral:\n",
    "                zones = {key: 1 for key in zones}  # all zones\n",
    "            if left:\n",
    "                zones['upper_left'] = 1\n",
    "                zones['middle_left'] = 1\n",
    "                zones['lower_left'] = 1\n",
    "            if right:\n",
    "                zones['upper_right'] = 1\n",
    "                zones['middle_right'] = 1\n",
    "                zones['lower_right'] = 1\n",
    "        \n",
    "    # return zones if any are detected, else N/A\n",
    "    return zones if any(zones.values()) else 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788f223-a0b5-4f9b-bda5-6814f6d77254",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/test_llm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0440ec-a5ad-4e26-8a84-f5258eddcfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing radiologist localisations from LLM responses and mapping them to lung zones\n",
    "\n",
    "mimic_llm = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia-full-wreports_llm_complete_frontal.csv')\n",
    "\n",
    "mimic_llm['LLM_loc'] = mimic_llm.LLM_Pneumonia.apply(lambda response : re.findall(r'LOCATION>(.*?)</LOCATION>', response.upper())[-1])\n",
    "mimic_llm['LLM_loc'] = mimic_llm['LLM_loc'].apply(lambda locs : ', '.join(ast.literal_eval(locs.strip())) if locs != 'NONE' and '[' in locs else 'N/A')\n",
    "mimic_llm['Mapped_Zones'] = mimic_llm.LLM_loc.apply(map_pneumonia_locs)\n",
    "\n",
    "mimic_llm['Processed_Path'] = mimic_llm.Path.apply(processed_file_name)\n",
    "positive_rows = mimic_llm[(mimic_llm.Processed_Path.isin(test_data[test_data.Label == 1].Path)) & (mimic_llm.Mapped_Zones != 'N/A')].reset_index(drop=True)\n",
    "\n",
    "positive_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71aeb4c-5ebc-4a12-bed6-fc9a888a14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = positive_rows.iloc[88]\n",
    "img_path,loc = data.Path,data.LLM_loc\n",
    "\n",
    "processor = CXR_Processor()\n",
    "original, processed = processor.load_and_process(img_path)\n",
    "cropped_img, cropped_mask, left_lung, right_lung = processor.crop_trunk(original, processed, .025, return_lungs=True)\n",
    "outlier_mask = processor.find_outliers(cropped_img, cropped_mask, lower_percentile=.1, outlier_thresh=.05)\n",
    "clahe_img = cv2.createCLAHE(clipLimit=2).apply(cropped_img)\n",
    "if outlier_mask is not None:\n",
    "    clahe_img[outlier_mask] = 0\n",
    "\n",
    "img = Image.fromarray(clahe_img).convert('RGB')\n",
    "img_tensor = process(img).unsqueeze(0).to(device)\n",
    "\n",
    "heatmap, pred_class_idx, confidence = grad_cam(img_tensor)\n",
    "heatmap, overlay_rgb = overlay_heatmap(heatmap, img, threshold=otsu(heatmap))\n",
    "\n",
    "if pred_class_idx == 1: # pneumonia-positive\n",
    "    pred_class = 'Pneumonia-positive'\n",
    "    combined_lungs = left_lung | right_lung\n",
    "    heatmap[~combined_lungs.cpu()] = 0\n",
    "\n",
    "    # renormalise\n",
    "    heatmap -= heatmap.min()\n",
    "    if heatmap.max() > 0:\n",
    "        heatmap /= heatmap.max()\n",
    "\n",
    "    upper_left, middle_left, lower_left = divide_lung(left_lung)\n",
    "    upper_right, middle_right, lower_right = divide_lung(right_lung)\n",
    "\n",
    "    frac_upper_left = heatmap[upper_left.cpu()].max().item()\n",
    "    frac_middle_left = heatmap[middle_left.cpu()].max().item()\n",
    "    frac_lower_left = heatmap[lower_left.cpu()].max().item()\n",
    "\n",
    "    frac_upper_right = heatmap[upper_right.cpu()].max().item()\n",
    "    frac_middle_right = heatmap[middle_right.cpu()].max().item()\n",
    "    frac_lower_right = heatmap[lower_right.cpu()].max().item()\n",
    "\n",
    "    mapping = {\n",
    "    'Upper Left': [frac_upper_left, upper_left],\n",
    "    'Middle Left': [frac_middle_left, middle_left],\n",
    "    'Lower Left': [frac_lower_left, lower_left],\n",
    "    'Upper Right': [frac_upper_right, upper_right],\n",
    "    'Middle Right': [frac_middle_right, middle_right],\n",
    "    'Lower Right': [frac_lower_right, lower_right]\n",
    "    }\n",
    "    locs,masks = zip(*[(key,mask) for key,(val,mask) in mapping.items() if val > .8])\n",
    "    locs = ', '.join(locs)\n",
    "\n",
    "    _,ax = plt.subplots(ncols=3, figsize=(12,8), constrained_layout=True)\n",
    "\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(f'Input Processed CXR\\nGround Truth: {loc.title()} Pneumonia')\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(overlay_rgb)\n",
    "    ax[1].set_title(f'Grad-CAM Overlay\\nDiagnosis: {pred_class} ({confidence:.2%})')\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    _, overlay_rgb = overlay_heatmap(heatmap, img)\n",
    "    ax[2].imshow(overlay_rgb)\n",
    "    ax[2].set_title(f'Maximum Activation per Lung Zone\\nLocalisation: {locs} Zone')\n",
    "\n",
    "    ax[2].contour(upper_left.cpu(), levels=[.5], colors='white', linewidths=2)\n",
    "    ax[2].contour(middle_left.cpu(), levels=[.5], colors='white', linewidths=2)\n",
    "    ax[2].contour(lower_left.cpu(), levels=[.5], colors='white', linewidths=2)\n",
    "\n",
    "    add_fraction_text(ax[2], upper_left,  frac_upper_left)\n",
    "    add_fraction_text(ax[2], middle_left,  frac_middle_left)\n",
    "    add_fraction_text(ax[2], lower_left,  frac_lower_left)\n",
    "\n",
    "    ax[2].contour(upper_right.cpu(), levels=[.5], colors='white', linewidths=2)\n",
    "    ax[2].contour(middle_right.cpu(), levels=[.5], colors='white', linewidths=2)\n",
    "    ax[2].contour(lower_right.cpu(), levels=[.5], colors='white', linewidths=2)\n",
    "\n",
    "    add_fraction_text(ax[2], upper_right,  frac_upper_right)\n",
    "    add_fraction_text(ax[2], middle_right,  frac_middle_right)\n",
    "    add_fraction_text(ax[2], lower_right,  frac_lower_right)\n",
    "\n",
    "    for mask in masks:\n",
    "        ax[2].contour(mask.cpu(), levels=[.5], colors='red', linewidths=2)\n",
    "        \n",
    "    ax[2].axis(\"off\")\n",
    "\n",
    "else:\n",
    "    print('\\nNegative prediction\\n')\n",
    "\n",
    "#plt.savefig('/Data/Figures/mimic_loc_3.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcac1f-be15-4b3b-a4c4-5773dbef36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CXR_Processor()\n",
    "\n",
    "all_zones = []\n",
    "\n",
    "for i in range(len(positive_rows)):\n",
    "    data = positive_rows.iloc[i]\n",
    "    path = data.Path\n",
    "\n",
    "    original, processed = processor.load_and_process(path)\n",
    "    cropped_img, cropped_mask, left_lung, right_lung = processor.crop_trunk(original, processed, .025, return_lungs=True)\n",
    "    outlier_mask = processor.find_outliers(cropped_img, cropped_mask, lower_percentile=.1, outlier_thresh=.05)\n",
    "    clahe_img = cv2.createCLAHE(clipLimit=2).apply(cropped_img)\n",
    "    if outlier_mask is not None:\n",
    "        clahe_img[outlier_mask] = 0\n",
    "\n",
    "    img = Image.fromarray(clahe_img).convert('RGB')\n",
    "    img_tensor = process(img).unsqueeze(0).to(device)\n",
    "\n",
    "    heatmap, pred_class_idx, confidence = grad_cam(img_tensor) # only positive predictions\n",
    "    #heatmap, pred_class_idx, confidence = grad_cam(img_tensor, class_idx=1) # all predictions\n",
    "    \n",
    "    if pred_class_idx == 1: # pneumonia-positive\n",
    "        heatmap, overlay_rgb = overlay_heatmap(heatmap, img, threshold=otsu(heatmap))\n",
    "\n",
    "        combined_lungs = left_lung | right_lung\n",
    "        heatmap[~combined_lungs.cpu()] = 0\n",
    "\n",
    "        # renormalise\n",
    "        heatmap -= heatmap.min()\n",
    "        if heatmap.max() > 0:\n",
    "            heatmap /= heatmap.max()\n",
    "\n",
    "        upper_left, middle_left, lower_left = divide_lung(left_lung)\n",
    "        upper_right, middle_right, lower_right = divide_lung(right_lung)\n",
    "\n",
    "        frac_upper_left = heatmap[upper_left.cpu()].max().item()\n",
    "        frac_middle_left = heatmap[middle_left.cpu()].max().item()\n",
    "        frac_lower_left = heatmap[lower_left.cpu()].max().item()\n",
    "\n",
    "        frac_upper_right = heatmap[upper_right.cpu()].max().item()\n",
    "        frac_middle_right = heatmap[middle_right.cpu()].max().item()\n",
    "        frac_lower_right = heatmap[lower_right.cpu()].max().item()\n",
    "        \n",
    "        thresh = .8\n",
    "        frac_upper_left = int(frac_upper_left > thresh)\n",
    "        frac_middle_left = int(frac_middle_left > thresh)\n",
    "        frac_lower_left = int(frac_lower_left > thresh)\n",
    "        frac_upper_right = int(frac_upper_right > thresh)\n",
    "        frac_middle_right = int(frac_middle_right > thresh)\n",
    "        frac_lower_right = int(frac_lower_right > thresh)\n",
    "\n",
    "        zones = {\n",
    "            'upper_left': frac_upper_left, 'middle_left': frac_middle_left, 'lower_left': frac_lower_left,\n",
    "            'upper_right': frac_upper_right, 'middle_right': frac_middle_right, 'lower_right': frac_lower_right\n",
    "        }\n",
    "        all_zones.append(zones)\n",
    "    else:\n",
    "        all_zones.append('N/A')\n",
    "\n",
    "all_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787c75a-7a4d-4bc5-aee4-ab7f1c7c74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted pneumonia-positive lung zones\n",
    "\n",
    "positive_rows['Pred_Zones'] = all_zones\n",
    "positive_rows = positive_rows[positive_rows.Pred_Zones != 'N/A'].reset_index(drop=True)\n",
    "\n",
    "positive_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12198e-c495-42db-abb9-a353ea674bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare reported and predicted lung zones\n",
    "\n",
    "evaluate_gradcam(positive_rows['Mapped_Zones'], positive_rows['Pred_Zones'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a639d9b-673e-4abb-84e9-359ffba7e878",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Failed Processing Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb4ba7-a56f-4e74-8960-bdcba67ec153",
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = pd.read_csv('/Data/CheX_Data/CheX_failed_cxrs.csv')\n",
    "failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129cfaab-6619-47bf-884e-75e50dcf1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_masks = failures[failures['Failure Reason'] == 'Lung mask(s) missing']['Image Path'].tolist()\n",
    "\n",
    "axes = 5\n",
    "indices = [np.random.randint(0,len(missing_masks)) for _ in range(axes)]\n",
    "\n",
    "_,ax = plt.subplots(ncols=axes, figsize=(15,5), constrained_layout=True)\n",
    "for i,idx in enumerate(indices):\n",
    "    ax[i].imshow(cv2.imread(missing_masks[idx], cv2.IMREAD_GRAYSCALE), cmap='gray')\n",
    "\n",
    "plt.suptitle('Missing Lung Mask(s)', y=.85, fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cddda5-19c6-4cd2-bdf1-63d478970d49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Delete Processed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678f256-f2d8-4518-a2c5-c45bebd42301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire dataset\n",
    "chex = pd.read_csv('/Data/CheX_Data/chexpertchestxrays-u20210408/train_cheXbert_w_views.csv')\n",
    "\n",
    "paths = chex.Path.apply(get_chex_img_path).tolist()\n",
    "processed_paths = [processed_file_name(path) for path in paths]\n",
    "existing_processed_paths = [path for path in processed_paths if os.path.isfile(path)]\n",
    "\n",
    "existing_processed_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ad2e8cc-efde-4b81-8d49-fb565652c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in existing_processed_paths:\n",
    "    os.remove(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
