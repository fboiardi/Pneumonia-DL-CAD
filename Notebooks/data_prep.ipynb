{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4852b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import ast, os, cv2, torch, shutil, pydicom\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c293c8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4dc74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsna = pd.read_csv('/Data/RSNA_Data/stage_2_train_labels.csv')\n",
    "nih = pd.read_csv('/Data/NIH_Data/Data_Entry_2017.csv')\n",
    "chex = pd.read_csv('/Data/CheX_Data/chexpertchestxrays-u20210408/train_cheXbert.csv') # recommended labels\n",
    "pad = pd.read_csv('/Data/BIMCV-PadChest-FULL/PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv', encoding='utf-8')\n",
    "mimic = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-2.0.0-chexpert.csv')\n",
    "vindr = pd.read_csv('/Data/VinDR_Data/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_merged.csv')\n",
    "\n",
    "mimic_meta = pd.read_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-2.0.0-metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b852c6-6354-4f8c-9f93-bb63318e967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples\n",
    "#chex.sample(n=10_000).to_csv('/Data/cheXbert_10K_sample.csv', index=False)\n",
    "#nih.sample(n=10_000).to_csv('/Data/nih_10K_sample.csv', index=False)\n",
    "#pad.sample(n=10_000).to_csv('/Data/pad_10K_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260cc5a2-1200-41fc-a0df-b18329f8e4b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Merging VinDR Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b8eca-59c8-46c3-be0e-25af3ff20873",
   "metadata": {},
   "outputs": [],
   "source": [
    "vindr_train = pd.read_csv('/Data/VinDR_Data/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_train.csv')\n",
    "\n",
    "# majority vote for pneumonia per image id\n",
    "def majority_vote(group):\n",
    "    majority_value = group['Pneumonia'].mode().iloc[0]\n",
    "    return group[group['Pneumonia'] == majority_value].iloc[0]\n",
    "\n",
    "vindr_train = vindr_train.groupby('image_id').apply(majority_vote).reset_index(drop=True)\n",
    "\n",
    "vindr_train['Set'] = ['train' for _ in range(len(vindr_train))]\n",
    "vindr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ecc8c-f705-4a36-ba3a-5c2ac5dc2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "vindr_test = pd.read_csv('/Data/VinDR_Data/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_test.csv')\n",
    "vindr_test['Set'] = ['test' for _ in range(len(vindr_test))]\n",
    "\n",
    "vindr_merged = pd.concat([vindr_train, vindr_test]).reset_index(drop=True)\n",
    "vindr_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a3d2b45-5f1f-4ebc-b425-6babc571bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vindr_merged.to_csv('/Data/VinDR_Data/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57424b7-b45c-4228-8e24-56098f1b8fe5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sorting MIMIC data by Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e3f75-3e88-4dfe-8672-a19d3d9f7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mimic = mimic[mimic.Pneumonia.isin((0,1))] # do not include for LLM relabelling\n",
    "mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78732f95-4d21-4646-8396-05f542ba2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "for _, row in mimic.iterrows():\n",
    "    patient, study = row.subject_id.astype(int), row.study_id.astype(int)\n",
    "    pneumonia_status = row.Pneumonia\n",
    "\n",
    "    study_path = f'/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p{str(patient)[:2]}/p{patient}/s{study}/'\n",
    "    images = [file for file in os.listdir(study_path) if file.endswith('.jpg')]\n",
    "\n",
    "    new_rows.extend([{'Path': study_path+image, 'Patient': patient, 'Pneumonia': pneumonia_status} for image in images])\n",
    "\n",
    "df = pd.DataFrame(new_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb892a3-36a3-4516-8e4c-697d3fee2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Pneumonia.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7eff815e-d4f7-4d21-8719-14c1099acb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia.csv', index=False) # only (0,1) pneumonia labels\n",
    "df.to_csv('/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-pneumonia-full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a5df4-ecd7-4ae0-9b9e-f8d4dc417833",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PadChest Localisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f4f37-a046-4375-82da-dc283f4ed0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_pneumonia = pad[pad.Labels.str.contains('pneumonia', na=False)]\n",
    "pneumonia_locs = []\n",
    "\n",
    "for i in range(len(pad_pneumonia)):\n",
    "    locs = ast.literal_eval(pad_pneumonia.LabelsLocalizationsBySentence.iloc[i])\n",
    "    for loc in locs:\n",
    "        if 'pneumonia' in loc:\n",
    "            filter_locs = [x[4:].capitalize() for x in loc if x.startswith('loc')]\n",
    "            if filter_locs:\n",
    "                pneumonia_locs.extend(filter_locs)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "_,ax = plt.subplots(1, figsize=(10,5))\n",
    "\n",
    "pd.Series(pneumonia_locs).value_counts()[:20].plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Localisation')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Top 20 Frequent Pneumonia Localisations - PadChest Dataset')\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('pneumonia_localisations.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4618ed-5a8e-47eb-a872-7c08a023bfec",
   "metadata": {},
   "source": [
    "# Accessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eba0e608-7212-4eb9-8144-0b72caa84b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chex_img_path(cheXbert_path:str) -> str:\n",
    "    path = '/Data/CheX_Data/chexpertchestxrays-u20210408/CheXpert-v1.0'\n",
    "    \n",
    "    patient_num = int(cheXbert_path[27:32])\n",
    "    if 1 <= patient_num <= 21513:\n",
    "        path += ' batch 2 (train 1)/'\n",
    "    elif 21514 <= patient_num <= 43017:\n",
    "        path += ' batch 3 (train 2)/'\n",
    "    elif 43018 <= patient_num <= 64540:\n",
    "        path += ' batch 4 (train 3)/'\n",
    "    else:\n",
    "        path += ' batch 1 (validate & csv)/valid/'\n",
    "\n",
    "    return path + cheXbert_path[20:]\n",
    "\n",
    "def get_nih_img_path(nih_img_idx:str) -> str:\n",
    "    path = '/Data/NIH_Data/'\n",
    "\n",
    "    # apologies...\n",
    "    img = nih_img_idx[:-4]\n",
    "    if '00000001_000' <= img <= '00001335_006':\n",
    "        path += f'images_001/images/{nih_img_idx}'\n",
    "    elif '00001336_000' <= img <= '00003923_013':\n",
    "        path += f'images_002/images/{nih_img_idx}'\n",
    "    elif '00003923_014' <= img <= '00006585_006':\n",
    "        path += f'images_003/images/{nih_img_idx}'\n",
    "    elif '00006585_007' <= img <= '00009232_003':\n",
    "        path += f'images_004/images/{nih_img_idx}'\n",
    "    elif '00009232_004' <= img <= '00011558_007':\n",
    "        path += f'images_005/images/{nih_img_idx}'\n",
    "    elif '00011558_008' <= img <= '00013774_025':\n",
    "        path += f'images_006/images/{nih_img_idx}'\n",
    "    elif '00013774_026' <= img <= '00016051_009':\n",
    "        path += f'images_007/images/{nih_img_idx}'\n",
    "    elif '00016051_010' <= img <= '00018387_034':\n",
    "        path += f'images_008/images/{nih_img_idx}'\n",
    "    elif '00018387_035' <= img <= '00020945_049':\n",
    "        path += f'images_009/images/{nih_img_idx}'\n",
    "    elif '00020945_050' <= img <= '00024717_000':\n",
    "        path += f'images_010/images/{nih_img_idx}'\n",
    "    elif '00024718_000' <= img <= '00028173_002':\n",
    "        path += f'images_011/images/{nih_img_idx}'\n",
    "    else:\n",
    "        path += f'images_012/images/{nih_img_idx}'\n",
    "\n",
    "    return path\n",
    "\n",
    "get_pad_img_path = lambda pad_row : f'/Data/BIMCV-PadChest-FULL/{pad_row[\"ImageDir\"]}/{pad_row[\"ImageID\"]}'\n",
    "\n",
    "get_vindr_img_path = lambda vindr_row : f'/Data/VinDR_Data/physionet.org/files/vindr-cxr/1.0.0/{vindr_row[\"Set\"]}/{vindr_row[\"image_id\"]}.dicom'\n",
    "\n",
    "get_rsna_img_path = lambda patientId : f'/Data/RSNA_Data/stage_2_train_images/{patientId}.dcm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b4b43-1d23-42f0-95c9-2f7d609663cd",
   "metadata": {},
   "source": [
    "# Frontal vs. Lateral Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900ea53-746b-4bad-8981-8dba08d848ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f7c7a-543a-46c6-b25d-6fa830fc9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained ResNet-50 model to distinguish frontal vs lateral CXRs\n",
    "resnet50 = models.resnet50()\n",
    "resnet50.fc = torch.nn.Linear(resnet50.fc.in_features, 2)\n",
    "\n",
    "state_dict = '/Data/jacky_models/resnet50_frontal_vs_lateral.pth'\n",
    "resnet50.load_state_dict(torch.load(state_dict, weights_only=True))\n",
    "\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "resnet50.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5cdc2900-c5e1-4361-84ac-005132680966",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def classify_chex_quality(cheXbert_path):\n",
    "    image_path = get_chex_img_path(cheXbert_path)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = resnet50(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return predicted.item()\n",
    "\n",
    "def classify_nih_quality(nih_img_idx):\n",
    "    image_path = get_nih_img_path(nih_img_idx)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = resnet50(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return predicted.item()\n",
    "\n",
    "def classify_pad_quality(pad_row):\n",
    "    image_path = get_pad_img_path(pad_row)\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    image_np = np.array(image, dtype=np.uint16)\n",
    "    image_np = cv2.normalize(image_np, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8) # scale to 8-bit\n",
    "\n",
    "    image = Image.fromarray(image_np, mode='L').convert('RGB')\n",
    "    \n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = resnet50(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return predicted.item()\n",
    "\n",
    "def classify_vindr_quality(vindr_row):\n",
    "    image_path = get_vindr_img_path(vindr_row)\n",
    "    \n",
    "    dicom = pydicom.dcmread(image_path)\n",
    "    image_np = dicom.pixel_array\n",
    "\n",
    "    # convert to standard grayscale\n",
    "    if dicom.PhotometricInterpretation == 'MONOCHROME1':\n",
    "        image_np = image_np.max() - image_np\n",
    "\n",
    "    # windowing\n",
    "    if 'WindowCenter' in dicom:\n",
    "        window_center = float(dicom.WindowCenter)\n",
    "        window_width = float(dicom.WindowWidth)\n",
    "\n",
    "        lower_bound = window_center - (window_width / 2)\n",
    "        upper_bound = window_center + (window_width / 2)\n",
    "        image_np = np.clip(image_np, lower_bound, upper_bound)\n",
    "\n",
    "    image_np = cv2.normalize(image_np, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    image = Image.fromarray(image_np, mode='L').convert('RGB')\n",
    "    \n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = resnet50(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return predicted.item()\n",
    "\n",
    "def classify_rsna_quality(rsna_path):\n",
    "    image_path = get_rsna_img_path(rsna_path)\n",
    "\n",
    "    dicom = pydicom.dcmread(image_path)\n",
    "    image_np = dicom.pixel_array\n",
    "\n",
    "    if dicom.PhotometricInterpretation == 'MONOCHROME1':\n",
    "        image_np = image_np.max() - image_np\n",
    "\n",
    "    if 'WindowCenter' in dicom:\n",
    "        window_center = float(dicom.WindowCenter)\n",
    "        window_width = float(dicom.WindowWidth)\n",
    "\n",
    "        lower_bound = window_center - (window_width / 2)\n",
    "        upper_bound = window_center + (window_width / 2)\n",
    "        image_np = np.clip(image_np, lower_bound, upper_bound)\n",
    "\n",
    "    image = Image.fromarray(image_np).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = resnet50(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76e06152-5766-4984-86ec-2945dd720594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chex['Pred_View'] = chex.Path.apply(classify_chex_quality)\n",
    "#nih['Pred_View'] = nih['Image Index'].apply(classify_nih_quality)\n",
    "pad['Pred_View'] = pad.apply(classify_pad_quality, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c76886",
   "metadata": {},
   "source": [
    "# Disagreements Between Reported/Predicted Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be5841-b730-4ffb-846f-7b8497134a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chex['Pred_View'] = chex['Pred_View'].apply(lambda val : 'Lateral' if val else 'Frontal')\n",
    "#chex['ViewAgreement'] = chex.apply(lambda row : row['Frontal/Lateral'] == row['Pred_View'], axis=1)\n",
    "\n",
    "#nih['Pred_View'] = nih['Pred_View'].apply(lambda val : 'Lateral' if val else 'Frontal')\n",
    "#nih['ViewAgreement'] = nih['Pred_View'].apply(lambda val : val == 'Frontal')\n",
    "\n",
    "pad['Pred_View'] = pad['Pred_View'].apply(lambda val : 'Lateral' if val else 'Frontal')\n",
    "pad['Frontal/Lateral'] = pad.Projection.apply(lambda view : 'Lateral' if view == 'L' else 'Frontal')\n",
    "pad['ViewAgreement'] = pad.apply(lambda row : row['Frontal/Lateral'] == row['Pred_View'], axis=1)\n",
    "\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a2a3c3b-208b-4b2a-b9ff-e3cf261ea777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chex.to_csv('/Data/CheX_Data/chexpertchestxrays-u20210408/train_cheXbert_w_views.csv', index=False)\n",
    "#nih.to_csv('/Data/NIH_Data/Data_Entry_2017_w_views.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78790209-aa2c-4724-aa60-41cf459886a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disagree = chex[chex.ViewAgreement == False]\n",
    "#disagree = nih[nih.ViewAgreement == False]\n",
    "disagree = pad[pad.ViewAgreement == False]\n",
    "\n",
    "disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c96987-97d7-4f9b-a779-b9505d6df71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disagree_paths = disagree.Path.apply(get_chex_img_path).tolist()\n",
    "#disagree_paths = disagree['Image Index'].apply(get_nih_img_path).tolist()\n",
    "disagree_paths = disagree.apply(get_pad_img_path, axis=1).tolist()\n",
    "\n",
    "disagree_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "330b23af-e4cc-4d6e-9051-ed84f7fd3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_dir = '/Data/CheX_view_disagreement/'\n",
    "target_dir = '/Data/Pad_view_disagreement/'\n",
    "\n",
    "for image_path in disagree_paths:\n",
    "    study_dir = os.path.basename(os.path.dirname(image_path))\n",
    "    patient_dir = os.path.basename(os.path.dirname(os.path.dirname(image_path)))\n",
    "\n",
    "    original_filename = os.path.basename(image_path)\n",
    "    new_filename = f'{patient_dir}_{study_dir}_{original_filename}'\n",
    "\n",
    "    dest_path = os.path.join(target_dir, new_filename)\n",
    "\n",
    "    shutil.copy(image_path, dest_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
